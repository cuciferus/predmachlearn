Practical Machine Learning
===

Load data
---

```{r}
library(caret)
testing<-read.csv('pml-testing.csv')
training<- read.csv('pml-training.csv')
```

Data cleaning
---
Drop useless(username, timestamps) and very incomplete columns. I've chosen a threshold of 0.1 of complete cases in each column.
I've also partitioned the training set into train and validation

```{r}
colid2remove <- function(df) {
    idx <- c()
    for (i in 1:dim(df)[2]) {
        if (sum(is.na(df[, i]))/dim(df)[1] > 0.1) 
            idx <- c(idx, i)
    }
    return(idx)
}
col2remove<-unique(c(colid2remove(training), colid2remove(testing)))
training<- training[,-c(col2remove)]
testing <-testing[,-c(col2remove)]
training <- training[,sapply(training, is.numeric)]
testing <- testing[,sapply(testing, is.numeric)]
inTrain <- createDataPartition(df$classe, p=0.7)[[1]]
train <- training[inTrain,]
validation <- training[-inTrain,]

```

Train
---
First I'll try a random forest beacause:
1.I like the name of the algorithm
2.It makes no assumption about the data
3.There are, even after data cleaning, a big number of predictors
4.Does not overfit
---
Forest, confusion matrix and var importance

```{r}
library(randomForest)
set.seed(1)
modelFit<- randomForest(classe ~., data=train, ntree=2048)
modelFit$confusion
importance<- varImp(modelFit)
importance$Variable <- row.names(importance)
importance[order(importance$Overall, decreasing=T),]
```

Prediction using randomForest

```{r}
predict(modelFit, tesing)
```

